{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "4. Embeddings and Sentiment Analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iaanimashaun/Strive-School-Assigments/blob/main/4_Embeddings_and_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv8Nv-jj_EFm"
      },
      "source": [
        "## Amazon, IMDB and Yelp Review Sentiment Classification using SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksd85mHt_EFz"
      },
      "source": [
        "# !pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxXpwEUW_EF0"
      },
      "source": [
        "# !pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEsDJKbn_EF0"
      },
      "source": [
        "# !python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TJP5fyx_EF1"
      },
      "source": [
        "#!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfxLSRY5_EF1"
      },
      "source": [
        "### Data Cleaning Options\n",
        "- Case Normalization\n",
        "- Removing Stop Words\n",
        "- Removing Punctuations or Special Symbols\n",
        "- Lemmatization or Stemming\n",
        "- Parts of Speech Tagging\n",
        "- Entity Detection\n",
        "- Bag of Words\n",
        "- TF-IDF "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojs9JgQ0_EF3"
      },
      "source": [
        "### Bag of Words - The Simplest Word Embedding Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW4sW3pY_EF3"
      },
      "source": [
        "This is one of the simplest methods of embedding words into numerical vectors. It is not often used in practice due to its oversimplification of language, but often the first embedding technique to be taught in the classroom setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvMhOwU_EF5"
      },
      "source": [
        "```\n",
        "doc1 = \"I am high\"\n",
        "doc2 = \"Yes I am high\"\n",
        "doc3 = \"I am kidding\" \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIhnfOdS_EF5"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoIs2PM__EF6"
      },
      "source": [
        "### Bag of Words and Tf-idf \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
        "\n",
        "tf–idf for “Term Frequency times Inverse Document Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L71zx4c_EF8"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQWLoUJ_EF9"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltnrlAY_EF-"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifx14YTX_EF-"
      },
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/Strive/Exercises/Module_7_NLP/Week_1/D4/4. Semantics and Embeddings/data/train_data.csv\", index_col=\"Unnamed: 0\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Strive/Exercises/Module_7_NLP/Week_1/D4/4. Semantics and Embeddings/data/data_yelp.csv\", index_col=\"Unnamed: 0\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU83OW4i_EF_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train_data['Review']\n",
        "y = train_data['Sentiment']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test = test_data['Review']\n",
        "y_test = test_data['Sentiment']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BCQqGgl_EF_"
      },
      "source": [
        "# Let's Get Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM2UOO-X_EGA"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYTY_ao9_EGA"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pC6E-VGG_EGB",
        "outputId": "906ee5c6-2a43-40ea-e5af-ca339d231cea"
      },
      "source": [
        "nlp(\"Hello\")[0].lemma_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hello'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wURvodXz_EGD"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "We need to create a function that given the text of a sentence preprocess it.\n",
        "\n",
        "Some of the operations we can do:\n",
        "- Case Normalization (automatic with lemmatization)\n",
        "- Removing Stop Words\n",
        "- Removing Punctuations or Special Symbols\n",
        "- Lemmatization or Stemming\n",
        "\n",
        "To insert it in a pipeline, you have to be sure that you start from a sentence and you get text tokens as output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj5IQ2in_EGE"
      },
      "source": [
        "def preprocessing(sentence):\n",
        "    # define your preprocessing pipeline\n",
        "\n",
        "    return [token.lemma_ for token in nlp(sentence) if not (token.is_punct and token.is_stop)]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8NOEws4_EGE"
      },
      "source": [
        "### Text Classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUA96HZu_EGE"
      },
      "source": [
        "import pandas as pd\n",
        "# import the tfidfvectorizer and the count vectorizer from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "# import the pipeline module from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import  Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLNx3HFy_EGF"
      },
      "source": [
        "# Define an instance of the TfidfVectorizer which receive your \n",
        "# preprocessing function\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=preprocessing)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aQJLW01_EGG"
      },
      "source": [
        "# Define an instance of the TfidfVectorizer which receive your \n",
        "# preprocessing function and it has as n-grams range (1,5)\n",
        "\n",
        "tfidf1_5 = TfidfVectorizer(tokenizer=preprocessing, ngram_range=(1,5))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN6aq2Hw_EGG"
      },
      "source": [
        "# Define an instance of the Countvectorizer which receive your \n",
        "# preprocessing function and it has as n-grams range (1,3)\n",
        "\n",
        "bow = CountVectorizer(tokenizer=preprocessing, ngram_range=(1,3))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MPctLKI_EGG"
      },
      "source": [
        "# define a word vectorizer that use the spacy's word vectors. Replace the\n",
        "# two comments with your code. If you don't remember how to access\n",
        "# the embeddings of a doc use dir(doc) and see if there is anything\n",
        "# that makes sense\n",
        "\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class WordVectorTransformer(TransformerMixin,BaseEstimator):\n",
        "    def __init__(self, model='en_core_web_sm'):\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self,X):\n",
        "        nlp = spacy.load(self.model)\n",
        "        return np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnLeFFBG_EGH"
      },
      "source": [
        "☝️In this case, however, we are not using our preprocessing pipeline and we are consider only sentence embeddings and not single token embeddings. In this way, it is more convenient because we have a single vector for each sentence and we can handle different length sentences. The vector representation for the entire Doc is calculated by averaging the vectors for each Token in the Doc.\n",
        "\n",
        "This may result in a less meaningful features than the one by using Tf-Idf for example. We will see how to handle this next week!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMEG3gtI_EGI"
      },
      "source": [
        "# import and load a classifier from sklearn. In class, I used \n",
        "# from sklearn.svm import LinearSVC\n",
        "# but feel free to experiment with other models\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "classifier = LinearSVC()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "BrvPaZxAKxPT",
        "outputId": "4c022b4f-1b9c-4c2e-94dc-45dc15802989"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0                           Wow... Loved this place.          1\n",
              "1                                 Crust is not good.          0\n",
              "2          Not tasty and the texture was just nasty.          0\n",
              "3  Stopped by during the late May bank holiday of...          1\n",
              "4  The selection on the menu was great and so wer...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGGuwec7_EGI",
        "outputId": "f642fd25-3233-412c-c8f7-d125b3437019"
      },
      "source": [
        "# Build a pipeline that contains only your tfidf and fit_transform it\n",
        "# on your corpus train_data[\"Review\"]\n",
        "\n",
        "pipe = Pipeline([\n",
        "                 ('tfidf', tfidf)\n",
        "])\n",
        "pipe.fit_transform(train_data['Review'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2748x4440 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 36360 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQP4DXjE_EGI"
      },
      "source": [
        "# Build a pipeline that contains your tfidf and the classifier\n",
        "pipe = Pipeline([\n",
        "                 ('tfidf', tfidf),\n",
        "                 ('classifier', classifier)\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2stffHuU_EGJ",
        "outputId": "4f3b2035-e572-4b72-af6b-96e8fc5e5fea"
      },
      "source": [
        "# fit on your data (X_train, y_train)\n",
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function preprocessing at 0x7f7f9ac83950>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE5LReS6_EGJ"
      },
      "source": [
        "# test on your validation data with the predict method\n",
        "\n",
        "y_pred = pipe.predict(X_val)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g8_hSkd_EGK",
        "outputId": "64c42619-623c-48c7-c759-58ca5c66b150"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       435\n",
            "           1       0.78      0.80      0.79       390\n",
            "\n",
            "    accuracy                           0.80       825\n",
            "   macro avg       0.80      0.80      0.80       825\n",
            "weighted avg       0.80      0.80      0.80       825\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1I5DQcn_EGK"
      },
      "source": [
        "# test on your test data\n",
        "\n",
        "y_pred_test = pipe.predict(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Az6dO7_EGK",
        "outputId": "681d8ea4-033e-402d-a704-4b2e95c6e617"
      },
      "source": [
        "print(classification_report(y_test, y_pred_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94       500\n",
            "           1       0.94      0.94      0.94       500\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.94      0.94      0.94      1000\n",
            "weighted avg       0.94      0.94      0.94      1000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpVG3PAV_EGK",
        "outputId": "a2a4cb9f-49ea-4741-f21f-02839700a8ba"
      },
      "source": [
        "confusion_matrix(y_val, y_pred)\n",
        "confusion_matrix(y_test, y_pred_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[468,  32],\n",
              "       [ 31, 469]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwSL4ALx_EGL",
        "outputId": "3fec9d56-ea58-4c2c-81e2-d3e520e7bd2e"
      },
      "source": [
        "# Test it with your examples\n",
        "pipe.predict(['Wow, this is amzing lesson'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG6Xa2vY_EGM",
        "outputId": "fbb0184f-8685-44d3-c036-6237ff3f66e2"
      },
      "source": [
        "pipe.predict(['Wow, this sucks'])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYKVTzwV_EGN",
        "outputId": "1118ff9d-6393-4703-9940-1d0cf9450aec"
      },
      "source": [
        "pipe.predict(['Worth of watching it. Please like it'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tquLzPo_EGN",
        "outputId": "842b3c9c-27f2-465e-fbba-87af83e83bca"
      },
      "source": [
        "pipe.predict(['Loved it. amazing'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZbvXRg2_EGO"
      },
      "source": [
        "Play with the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34OIp2t7_EGO"
      },
      "source": [
        "# !pip install whatlies\n",
        "# !pip install whatlies\\[umap\\]\n",
        "# !pip install delayed"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf_riJ-2Lgr_",
        "outputId": "45f4c3c6-1c16-4745-ff33-a983e0046375"
      },
      "source": [
        "from whatlies import EmbeddingSet\n",
        "from whatlies.language import CountVectorLanguage"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "mBseoXbL_EGO",
        "outputId": "df4a3f79-cc96-457b-c03e-3d64669bf7f8"
      },
      "source": [
        "\n",
        "\n",
        "lang = CountVectorLanguage(n_components=2, ngram_range=(1, 1), analyzer=\"word\")\n",
        "words = ['great', 'bad', 'amazing', 'sad', 'awesome', 'good', 'upset', \"nice\"]\n",
        "\n",
        "emb = lang[words]\n",
        "emb.plot_interactive(x_axis='good', y_axis='bad')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.LayerChart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-7f7c5cd848714d9d97f36e739fa781b2\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-7f7c5cd848714d9d97f36e739fa781b2\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-7f7c5cd848714d9d97f36e739fa781b2\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"name\"}, {\"type\": \"nominal\", \"field\": \"original\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"good\"}, \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"bad\"}, \"field\": \"y_axis\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"good vs. bad\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"type\": \"nominal\", \"field\": \"original\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_axis\"}}}], \"data\": {\"name\": \"data-fc32dbf596b64734cb717f64d73c5be3\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-fc32dbf596b64734cb717f64d73c5be3\": [{\"x_axis\": -0.29557829812355485, \"y_axis\": 0.3160903178135209, \"name\": \"great\", \"original\": \"great\"}, {\"x_axis\": -1.738945745308887, \"y_axis\": 1.0, \"name\": \"bad\", \"original\": \"bad\"}, {\"x_axis\": 0.0, \"y_axis\": 0.0, \"name\": \"amazing\", \"original\": \"amazing\"}, {\"x_axis\": -1.159297163539258, \"y_axis\": 0.6666666666666666, \"name\": \"sad\", \"original\": \"sad\"}, {\"x_axis\": 3.242547476676683, \"y_axis\": -0.04774766920838372, \"name\": \"awesome\", \"original\": \"awesome\"}, {\"x_axis\": 1.0, \"y_axis\": -0.20977420546619777, \"name\": \"good\", \"original\": \"good\"}, {\"x_axis\": -0.8042093089816652, \"y_axis\": 0.6451128972669011, \"name\": \"upset\", \"original\": \"upset\"}, {\"x_axis\": -0.1420351418230371, \"y_axis\": 0.00862150775990622, \"name\": \"nice\", \"original\": \"nice\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBXmcYQY_EGP",
        "outputId": "c780b5d0-b0eb-4f6e-c1d7-2f0742528565"
      },
      "source": [
        "\n",
        "from whatlies import EmbeddingSet\n",
        "from whatlies.language import SpacyLanguage\n",
        "\n",
        "lang = SpacyLanguage('en_core_web_lg') # lg is more accurate for this than sm\n",
        "words = ['cat', 'dog', 'fish', 'kitten', 'man', 'woman', 'king', 'queen', 'doctor', 'nurse', \"animal\", \"human\"]\n",
        "\n",
        "emb = lang[words]\n",
        "emb.plot_interactive(x_axis='animal', y_axis='human')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-47cb24d96a5547d6aab6a02f824212c3\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-47cb24d96a5547d6aab6a02f824212c3\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-47cb24d96a5547d6aab6a02f824212c3\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"name\"}, {\"type\": \"nominal\", \"field\": \"original\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"animal\"}, \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"human\"}, \"field\": \"y_axis\"}}, \"selection\": {\"selector002\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"animal vs. human\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"type\": \"nominal\", \"field\": \"original\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_axis\"}}}], \"data\": {\"name\": \"data-9ee7abd251423843c65ec4425b34b65e\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-9ee7abd251423843c65ec4425b34b65e\": [{\"x_axis\": 0.6187601685523987, \"y_axis\": 0.33100512623786926, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 0.6887070536613464, \"y_axis\": 0.3666931092739105, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 0.5427215099334717, \"y_axis\": 0.32445940375328064, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 0.5167830586433411, \"y_axis\": 0.23111103475093842, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": 0.3444931209087372, \"y_axis\": 0.4047676920890808, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": 0.36667153239250183, \"y_axis\": 0.4287062883377075, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": 0.2283821851015091, \"y_axis\": 0.20056787133216858, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": 0.22773508727550507, \"y_axis\": 0.18769921362400055, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": 0.3157787024974823, \"y_axis\": 0.3194921910762787, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": 0.3448294699192047, \"y_axis\": 0.24993661046028137, \"name\": \"nurse\", \"original\": \"nurse\"}, {\"x_axis\": 1.0, \"y_axis\": 0.596678614616394, \"name\": \"animal\", \"original\": \"animal\"}, {\"x_axis\": 0.6163212656974792, \"y_axis\": 1.0, \"name\": \"human\", \"original\": \"human\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.LayerChart(...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FitutlKC_EGP",
        "outputId": "392c4c15-3099-4bff-927f-4b12958d15b4"
      },
      "source": [
        "from whatlies.transformers import Pca, Umap\n",
        "\n",
        "orig_chart = emb.plot_interactive('man', 'woman')\n",
        "pca_plot = emb.transform(Pca(2)).plot_interactive()\n",
        "umap_plot = emb.transform(Umap(2)).plot_interactive()\n",
        "\n",
        "pca_plot | umap_plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/homebrew/anaconda3/envs/spacyenv/lib/python3.9/site-packages/umap/umap_.py:2213: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
            "  warn(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-351e4b9275e145adbc44614097d13dd3\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-351e4b9275e145adbc44614097d13dd3\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-351e4b9275e145adbc44614097d13dd3\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"name\"}, {\"type\": \"nominal\", \"field\": \"original\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Dimension 0\"}, \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Dimension 1\"}, \"field\": \"y_axis\"}}, \"selection\": {\"selector005\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Dimension 0 vs. Dimension 1\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"type\": \"nominal\", \"field\": \"original\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_axis\"}}}], \"data\": {\"name\": \"data-11de191232dc8ba7b82c3defe27dc187\"}}, {\"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"\", \"legend\": null}, \"tooltip\": [{\"type\": \"nominal\", \"field\": \"name\"}, {\"type\": \"nominal\", \"field\": \"original\"}], \"x\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Dimension 0\"}, \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"axis\": {\"title\": \"Dimension 1\"}, \"field\": \"y_axis\"}}, \"selection\": {\"selector006\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"Dimension 0 vs. Dimension 1\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"type\": \"nominal\", \"field\": \"original\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"x_axis\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y_axis\"}}}], \"data\": {\"name\": \"data-dced5913f5f2a1dcc23f4dfa69fa5e3a\"}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-11de191232dc8ba7b82c3defe27dc187\": [{\"x_axis\": 3.589444398880005, \"y_axis\": 0.8288776278495789, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 3.6729319095611572, \"y_axis\": 0.33565881848335266, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 1.5428708791732788, \"y_axis\": 1.5686591863632202, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 3.5905563831329346, \"y_axis\": 0.2780793309211731, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": -1.3038556575775146, \"y_axis\": -0.5415514707565308, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": -1.6689035892486572, \"y_axis\": -1.9887049198150635, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": -3.2824392318725586, \"y_axis\": 4.156259059906006, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": -3.136977434158325, \"y_axis\": 3.0538346767425537, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": -1.4553258419036865, \"y_axis\": -3.6299474239349365, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": -1.5483019351959229, \"y_axis\": -4.061163902282715, \"name\": \"nurse\", \"original\": \"nurse\"}], \"data-dced5913f5f2a1dcc23f4dfa69fa5e3a\": [{\"x_axis\": 1.1677545309066772, \"y_axis\": 16.687944412231445, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 0.9610953330993652, \"y_axis\": 15.319742202758789, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 1.3914313316345215, \"y_axis\": 15.943536758422852, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 0.5270827412605286, \"y_axis\": 16.456012725830078, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": 0.1671452820301056, \"y_axis\": 15.600610733032227, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": -0.6893158555030823, \"y_axis\": 15.87593936920166, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": -0.06520623713731766, \"y_axis\": 14.757275581359863, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": -0.8411046862602234, \"y_axis\": 14.993951797485352, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": -0.8071979880332947, \"y_axis\": 16.885278701782227, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": -0.3303024470806122, \"y_axis\": 16.528451919555664, \"name\": \"nurse\", \"original\": \"nurse\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.HConcatChart(...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTmSZwBg_EGQ"
      },
      "source": [
        "Play with similarities of sentences/tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XjYvuEY_EGR",
        "outputId": "d25569be-2117-441d-cd68-17c3e2817fcb"
      },
      "source": [
        "dog = nlp(\"dog\")\n",
        "cat = nlp(\"cat\")\n",
        "\n",
        "# Compare the similarity between Tokens 'dog' and 'cat'\n",
        "dog.similarity(cat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-71-d8d184b3019c>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  dog.similarity(cat)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7345952141306641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeYIJh9h_EGS",
        "outputId": "9c834535-6c04-415b-dcd9-28dc48b6911c"
      },
      "source": [
        "dog = nlp(\"dog\")\n",
        "queen = nlp(\"queen\")\n",
        "\n",
        "# Compare the similarity between Tokens 'dog' and 'cat'\n",
        "dog.similarity(queen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-74-6553aef6e761>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  dog.similarity(queen)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39438143492304706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLCJS4-c_EGS",
        "outputId": "516b87ec-59a4-416a-db2c-d35f3ff55f95"
      },
      "source": [
        "king = nlp(\"king\")\n",
        "man = nlp(\"man\")\n",
        "\n",
        "# Compare the similarity between Tokens 'dog' and 'cat'\n",
        "king.similarity(queen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-77-8cead224a31c>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  king.similarity(queen)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8043196533418226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdHzzTsv_EGV",
        "outputId": "a574deeb-3f94-4897-baec-b420740c6556"
      },
      "source": [
        "king = nlp(\"king\")\n",
        "woman = nlp(\"woman\")\n",
        "\n",
        "# Compare the similarity between Tokens 'dog' and 'cat'\n",
        "king.similarity(woman)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-78-f3731d4f914a>:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  king.similarity(woman)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8453325361917157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpx2aLm9_EGW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}